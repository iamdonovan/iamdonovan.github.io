<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>object-based classification &mdash; iamdonovan  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="change detection" href="../change_detection/index.html" />
    <link rel="prev" title="pixel-based classification" href="pixel.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> iamdonovan
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../whataboutbob.html">about me</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../teaching/index.html">teaching and related resources</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">google earth engine</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">gee tutorials</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../index.html#getting-an-earth-engine-account">getting an earth engine account</a></li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#script-repository">script repository</a></li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#data-catalog">data catalog</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../index.html#contents">contents</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../getting_started/index.html">getting started</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="index.html">image classification</a><ul class="current">
<li class="toctree-l5"><a class="reference internal" href="unsupervised.html">unsupervised classification</a></li>
<li class="toctree-l5"><a class="reference internal" href="pixel.html">pixel-based classification</a></li>
<li class="toctree-l5 current"><a class="current reference internal" href="#">object-based classification</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#image-segmentation">image segmentation</a></li>
<li class="toctree-l6"><a class="reference internal" href="#image-texture">image texture</a></li>
<li class="toctree-l6"><a class="reference internal" href="#classification">classification</a></li>
<li class="toctree-l6"><a class="reference internal" href="#exporting-the-classification">exporting the classification</a></li>
<li class="toctree-l6"><a class="reference internal" href="#next-steps">next steps</a></li>
<li class="toctree-l6"><a class="reference internal" href="#references-and-notes">references and notes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../change_detection/index.html">change detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../enhancement/index.html">image enhancement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../advanced/index.html">advanced topics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#references">references</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../exercises/index.html">sample exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../research/index.html">ongoing and past research projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../github.html">github projects</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">iamdonovan</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">google earth engine</a> &raquo;</li>
          <li><a href="../index.html">gee tutorials</a> &raquo;</li>
          <li><a href="index.html">image classification</a> &raquo;</li>
      <li>object-based classification</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/gee/tutorials/classification/obia.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="object-based-classification">
<h1>object-based classification<a class="headerlink" href="#object-based-classification" title="Permalink to this headline"></a></h1>
<section id="image-segmentation">
<h2>image segmentation<a class="headerlink" href="#image-segmentation" title="Permalink to this headline"></a></h2>
<p>The last few sections of the practical will take us through an example of object-based classification, to illustrate some of the differences
between object-based image analysis (OBIA) and pixel-based classification.</p>
<p>Start by uncommenting the first part of this section (remove the <code class="docutils literal notranslate"><span class="pre">/*</span></code> from line 203 and the <code class="docutils literal notranslate"><span class="pre">*/</span></code> from line 241). The following lines of code:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="c1">// set parameters for the size of the seeds and clusters for image segmentation</span>
<span class="c1">// 4 appears to be the minimum value for seed size</span>
<span class="kd">var</span> <span class="nx">seedSize</span> <span class="o">=</span> <span class="mf">4</span><span class="p">;</span> <span class="c1">//corresponds to 4 * 30 = 120 m spacing;</span>
<span class="kd">var</span> <span class="nx">clusterScale</span> <span class="o">=</span> <span class="mf">30</span><span class="p">;</span>

<span class="c1">// create a layer to seed the segmentation algorithm</span>
<span class="kd">var</span> <span class="nx">seeds</span> <span class="o">=</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Algorithms</span><span class="p">.</span><span class="nx">Image</span><span class="p">.</span><span class="nx">Segmentation</span><span class="p">.</span><span class="nx">seedGrid</span><span class="p">(</span><span class="nx">seedSize</span><span class="p">);</span>

<span class="c1">// run simple non-iterative clustering (SNIC) on the image, using our seed layer</span>
<span class="kd">var</span> <span class="nx">snic</span> <span class="o">=</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Algorithms</span><span class="p">.</span><span class="nx">Image</span><span class="p">.</span><span class="nx">Segmentation</span><span class="p">.</span><span class="nx">SNIC</span><span class="p">({</span>
  <span class="nx">image</span><span class="o">:</span> <span class="nx">img</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s1">&#39;SR_B.&#39;</span><span class="p">),</span>
  <span class="nx">compactness</span><span class="o">:</span> <span class="mf">0</span><span class="p">,</span>
  <span class="nx">connectivity</span><span class="o">:</span> <span class="mf">4</span><span class="p">,</span>
  <span class="nx">neighborhoodSize</span><span class="o">:</span> <span class="mf">128</span><span class="p">,</span>
  <span class="nx">seeds</span><span class="o">:</span> <span class="nx">seeds</span>
<span class="p">});</span>
</pre></div>
</div>
<p>will use an algorithm called simple non-iterative clustering (SNIC; Achanta and Susstrunk, 2017<a class="footnote-reference brackets" href="#id4" id="id1">3</a>) to segment our image,
creating the objects that we’ll use for the classification. This section starts by setting two parameters,
<code class="docutils literal notranslate"><span class="pre">seedSize</span></code> and <code class="docutils literal notranslate"><span class="pre">clusterScale</span></code>. I’ve added these here, rather than using the values directly in the
code below, so that it’s easier to change the values if we want to experiment later on.</p>
<p>The next block of code will create a vector layer from the objects, fixed at a specific scale (here, 30 m, corresponding to the original image resolution).
We can then add a layer to the map that shows the boundaries of the objects.</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="c1">// select the clusters (image segments, or objects) from our snic layer</span>
<span class="kd">var</span> <span class="nx">clusters</span> <span class="o">=</span> <span class="nx">snic</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s2">&quot;clusters&quot;</span><span class="p">);</span>

<span class="c1">// visualize the clusters by creating vectors, then displaying the outlines</span>
<span class="kd">var</span> <span class="nx">vectors</span> <span class="o">=</span> <span class="nx">clusters</span><span class="p">.</span><span class="nx">reduceToVectors</span><span class="p">({</span>
  <span class="nx">geometryType</span><span class="o">:</span> <span class="s1">&#39;polygon&#39;</span><span class="p">,</span>
  <span class="nx">reducer</span><span class="o">:</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Reducer</span><span class="p">.</span><span class="nx">countEvery</span><span class="p">(),</span>
  <span class="nx">scale</span><span class="o">:</span> <span class="nx">clusterScale</span><span class="p">,</span>
  <span class="nx">maxPixels</span><span class="o">:</span> <span class="mf">1e13</span><span class="p">,</span>
  <span class="nx">geometry</span><span class="o">:</span> <span class="nx">boundary</span><span class="p">,</span>
<span class="p">});</span>

<span class="kd">var</span> <span class="nx">empty</span> <span class="o">=</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Image</span><span class="p">().</span><span class="kr">byte</span><span class="p">();</span>

<span class="kd">var</span> <span class="nx">outline</span> <span class="o">=</span> <span class="nx">empty</span><span class="p">.</span><span class="nx">paint</span><span class="p">({</span>
  <span class="nx">featureCollection</span><span class="o">:</span> <span class="nx">vectors</span><span class="p">,</span>
  <span class="nx">color</span><span class="o">:</span> <span class="mf">1</span><span class="p">,</span>
  <span class="nx">width</span><span class="o">:</span> <span class="mf">1</span>
<span class="p">});</span>

<span class="nb">Map</span><span class="p">.</span><span class="nx">addLayer</span><span class="p">(</span><span class="nx">outline</span><span class="p">,</span> <span class="p">{</span><span class="nx">palette</span><span class="o">:</span> <span class="s1">&#39;669999&#39;</span><span class="p">},</span> <span class="s1">&#39;segments&#39;</span><span class="p">,</span> <span class="kc">false</span><span class="p">);</span>
</pre></div>
</div>
<p>Run the script, then toggle the <code class="docutils literal notranslate"><span class="pre">segments</span></code> layer on - you should see the outlines layer, with the original false color image underneath.
Zoom in to have a look around - how do the object boundaries you see relate to the image underneath? Do they agree? Are there areas where
the boundaries vary significantly from what you can see in the underlying image?</p>
<a class="reference internal image-reference" href="../../../_images/segmented_image.png"><img alt="a satellite image and image segments" class="align-center" src="../../../_images/segmented_image.png" style="width: 600px;" /></a>
<p>One thing to note here is that SNIC starts with a grid spaced by <code class="docutils literal notranslate"><span class="pre">seedSize</span></code> pixels and uses this to segment the image - the objects
that we end up with depends on the size of the grid that we start with. To illustrate this, uncomment
(remove the <code class="docutils literal notranslate"><span class="pre">/*</span></code> from line 243 and the <code class="docutils literal notranslate"><span class="pre">*/</span></code> from line 277) and run the script again.</p>
<p>The only change I’ve made here is to create a seed grid with twice the spacing as the original:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="c1">// create a layer to seed the segmentation algorithm</span>
<span class="kd">var</span> <span class="nx">seeds</span> <span class="o">=</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Algorithms</span><span class="p">.</span><span class="nx">Image</span><span class="p">.</span><span class="nx">Segmentation</span><span class="p">.</span><span class="nx">seedGrid</span><span class="p">(</span><span class="mf">2</span> <span class="o">*</span> <span class="nx">seedSize</span><span class="p">);</span>
</pre></div>
</div>
<p>After that, the code is mostly the same (aside from a color change for the <code class="docutils literal notranslate"><span class="pre">coarse</span> <span class="pre">segements</span></code> layer). Zoom in on some of the lakes
North of the peak - you should notice that some of the objects for some of the lakes using the coarser seed grid include both “lake”
and “not lake”, while the original boundaries do a decent job of picking the shorelines:</p>
<a class="reference internal image-reference" href="../../../_images/segmentation_comparison.png"><img alt="a comparison of two segmentation scales" class="align-center" src="../../../_images/segmentation_comparison.png" style="width: 600px;" /></a>
<p>This is something to keep in mind - the scale of our segmentation determines the size of the objects that we end up with. If we segment the image
too coarsely, we may end up losing detail that we’re interested in.</p>
<p>Once you’ve had a look around, go ahead and re-comment the coarse segmentation section (add a <code class="docutils literal notranslate"><span class="pre">/*</span></code> to line 243 and a <code class="docutils literal notranslate"><span class="pre">*/</span></code> to line 277), then
move on to the next section.</p>
</section>
<section id="image-texture">
<h2>image texture<a class="headerlink" href="#image-texture" title="Permalink to this headline"></a></h2>
<p>One of the things that we can do with OBIA that is more difficult to incorporate into pixel-based analysis is use image properties such
as texture or contrast, or even the shape of our segments, to aid our classification.</p>
<p>Here, we’ll have a look at including texture into our classification using metrics extracted using the Gray Level Co-occurrence
Matrix (GLCM; Haralick et al., 1973<a class="footnote-reference brackets" href="#id5" id="id2">4</a>). The GLCM contains information about how frequently combinations of pixel values appear
in a specified relationship in the image. We can use this, and the statistical metrics that we can extract from the GLCM,
to analyze the texture of the image.</p>
<p>Here, we’ll look at three examples: the Angular Second Moment (ASM), the local contrast, and the entropy. The Angular Second Moment measures how many
repeated pairs of values we see within each small window. The local contrast tells us how much variation we see in the small area, and the
entropy measures the randomness of the values in each small window.</p>
<p>Uncomment the lines in this section (remove the <code class="docutils literal notranslate"><span class="pre">/*</span></code> from line 280 and the <code class="docutils literal notranslate"><span class="pre">*/</span></code> from line 301), then run the script.</p>
<p>Before we compute the GLCM, we make a grayscale image from the NIR, Red, and Green bands, following Tassi and Vizzari (2020)<a class="footnote-reference brackets" href="#id6" id="id3">5</a>:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="c1">// create a grayscale image to run texture on, following Tassi and Vizzari (2020)</span>
<span class="c1">// paper: https://doi.org/10.3390/rs12223776</span>
<span class="c1">// GEE script: https://code.earthengine.google.com/?accept_repo=users/mvizzari/Tassi_Vizzari_RS2020</span>
<span class="kd">var</span> <span class="nx">gray</span> <span class="o">=</span> <span class="nx">img</span><span class="p">.</span><span class="nx">expression</span><span class="p">(</span>
  <span class="s1">&#39;(0.3 * NIR) + (0.59 * R) + (0.11 * G)&#39;</span><span class="p">,</span>
  <span class="p">{</span><span class="s1">&#39;NIR&#39;</span><span class="o">:</span> <span class="nx">img</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s1">&#39;SR_B5&#39;</span><span class="p">),</span>
   <span class="s1">&#39;R&#39;</span><span class="o">:</span> <span class="nx">img</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s1">&#39;SR_B4&#39;</span><span class="p">),</span>
   <span class="s1">&#39;G&#39;</span><span class="o">:</span> <span class="nx">img</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s1">&#39;SR_B3&#39;</span><span class="p">)</span>
<span class="p">}).</span><span class="nx">rename</span><span class="p">(</span><span class="s1">&#39;gray&#39;</span><span class="p">);</span>

<span class="nb">Map</span><span class="p">.</span><span class="nx">addLayer</span><span class="p">(</span><span class="nx">gray</span><span class="p">,</span> <span class="p">{</span><span class="nx">min</span><span class="o">:</span> <span class="mf">7500</span><span class="p">,</span> <span class="nx">max</span><span class="o">:</span> <span class="mf">17500</span><span class="p">},</span> <span class="s1">&#39;grayscale&#39;</span><span class="p">,</span> <span class="kc">false</span><span class="p">);</span>
</pre></div>
</div>
<p>this helps simplify the process somewhat - as we’ve seen in the lectures, there is often redundant information in nearby bands.</p>
<p>Once we’ve created this layer, we compute the GLCM and display the three images we’re interested in (the ASM, Contrast, and Entropy).</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="c1">// get the GLCM for the grayscale image</span>
<span class="kd">var</span> <span class="nx">glcm</span> <span class="o">=</span> <span class="nx">gray</span><span class="p">.</span><span class="nx">toInt</span><span class="p">().</span><span class="nx">glcmTexture</span><span class="p">({</span><span class="nx">size</span><span class="o">:</span> <span class="mf">2</span><span class="p">})</span>
  <span class="p">.</span><span class="nx">reproject</span><span class="p">({</span><span class="nx">crs</span><span class="o">:</span> <span class="nx">gray</span><span class="p">.</span><span class="nx">projection</span><span class="p">(),</span> <span class="nx">scale</span><span class="o">:</span> <span class="mf">30</span><span class="p">});</span>

<span class="nx">print</span><span class="p">(</span><span class="s1">&#39;GLCM Image&#39;</span><span class="p">,</span> <span class="nx">glcm</span><span class="p">);</span>
<span class="nb">Map</span><span class="p">.</span><span class="nx">addLayer</span><span class="p">(</span><span class="nx">glcm</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s1">&#39;gray_asm&#39;</span><span class="p">),</span> <span class="p">{</span><span class="nx">min</span><span class="o">:</span> <span class="mf">0.0281</span><span class="p">,</span> <span class="nx">max</span><span class="o">:</span> <span class="mf">0.0354</span><span class="p">},</span> <span class="s1">&#39;ASM&#39;</span><span class="p">,</span> <span class="kc">false</span><span class="p">);</span>
<span class="nb">Map</span><span class="p">.</span><span class="nx">addLayer</span><span class="p">(</span><span class="nx">glcm</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s1">&#39;gray_contrast&#39;</span><span class="p">),</span> <span class="p">{</span><span class="nx">min</span><span class="o">:</span> <span class="mf">3e5</span><span class="p">,</span> <span class="nx">max</span><span class="o">:</span> <span class="mf">5e6</span><span class="p">},</span> <span class="s1">&#39;Contrast&#39;</span><span class="p">,</span> <span class="kc">false</span><span class="p">);</span>
<span class="nb">Map</span><span class="p">.</span><span class="nx">addLayer</span><span class="p">(</span><span class="nx">glcm</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s1">&#39;gray_ent&#39;</span><span class="p">),</span> <span class="p">{</span><span class="nx">min</span><span class="o">:</span> <span class="mf">3.391</span><span class="p">,</span> <span class="nx">max</span><span class="o">:</span> <span class="mf">3.577</span><span class="p">},</span> <span class="s1">&#39;Entropy&#39;</span><span class="p">,</span> <span class="kc">false</span><span class="p">);</span>
</pre></div>
</div>
<p>The result of this is an image, <code class="docutils literal notranslate"><span class="pre">glcm</span></code>, that contains 18 variables for each band in the original image. For a full list of the variables,
you can see the <a class="reference external" href="https://developers.google.com/earth-engine/apidocs/ee-image-glcmtexture">documentation</a>. You can also see a list of the
bands for the <code class="docutils literal notranslate"><span class="pre">glcm</span></code> image in the <strong>Console</strong>.</p>
<p>Finally, have a look at the images that have been loaded in the map: the Angular Second Moment (ASM), the Contrast, and the Entropy.
Take a look at the ASM image first:</p>
<a class="reference internal image-reference" href="../../../_images/asm.png"><img alt="an image showing the angular second moment in the grayscale image" class="align-center" src="../../../_images/asm.png" style="width: 600px;" /></a>
<p>Remember that this tells us something about the repeated pairs of values within the specified window (here, a window of size 2) - brighter
colors indicate higher values (more repeated values), darker colors indicate lower values
(fewer repeated values). Before moving on to the contrast image, see if you can answer the following questions:</p>
<ul>
<li><p>Where do you see the most repeated values (brightest “colors”)?</p>
<blockquote>
<div><ul class="simple">
<li><p>What surfaces do these values represent?</p></li>
<li><p>Why do you think this would be so?</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Look at the grayscale image (toggle it on in the <strong>Layers</strong>). How does the image that you see here compare to the ASM image? That is, where do you see more variation in the “color” values?</p></li>
</ul>
<p>Now, have a look at the Contrast layer:</p>
<a class="reference internal image-reference" href="../../../_images/contrast.png"><img alt="an image showing the local contrast in the grayscale image" class="align-center" src="../../../_images/contrast.png" style="width: 600px;" /></a>
<p>Here, the bright colors represent the greatest contrast (i.e., difference) in values within the given window. In a way, this is showing us the same sort
of information as the ASM layer - high contrast indicates more variation (and therefore fewer repeated values), while low contrast indicates less variation
(and therefore more repeated values).</p>
<p>Finally, have a look at the Entropy layer:</p>
<a class="reference internal image-reference" href="../../../_images/entropy.png"><img alt="an image showing the local entropy in the grayscale image" class="align-center" src="../../../_images/entropy.png" style="width: 600px;" /></a>
<p>This is almost the inverse of the ASM layer - areas with high ASM values typically have lower Entropy. This makes some level of sense, given that more repeat
values implies that the distribution is likely less random than values that are more spread out.</p>
<p>Try to compare the three images some more. What patterns do you see in the contrast image? How could you use the texture information to help differentiate
between, for example, the surfaces on north flank of the volcano and the clear-cut areas in the southwest of the image, which have similar values in the
grayscale image?</p>
<p>Once you’ve spent some time thinking about these questions, move on to the next section, where we’ll add the texture bands to our image, and use this to classify
the scene using OBIA.</p>
</section>
<section id="classification">
<h2>classification<a class="headerlink" href="#classification" title="Permalink to this headline"></a></h2>
<p>Now that we’ve segmented the image and had a look at the image texture, we’ll move on to actually classifying the image using OBIA.</p>
<p>Uncomment the first part of this section section (remove the <code class="docutils literal notranslate"><span class="pre">/*</span></code> from line 304 and the <code class="docutils literal notranslate"><span class="pre">*/</span></code> from line 370), then run the script.
The first block of code in this section:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="c1">// get the vector labels</span>
<span class="kd">var</span> <span class="nx">labels</span> <span class="o">=</span> <span class="nx">vectors</span>
  <span class="p">.</span><span class="nx">reduceToImage</span><span class="p">({</span>
    <span class="nx">properties</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">],</span>
    <span class="nx">reducer</span><span class="o">:</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Reducer</span><span class="p">.</span><span class="nx">first</span><span class="p">()</span>
<span class="p">}).</span><span class="nx">rename</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">).</span><span class="nx">toInt</span><span class="p">();</span>

<span class="c1">// add the id layer to the image</span>
<span class="nx">img</span> <span class="o">=</span> <span class="nx">img</span><span class="p">.</span><span class="nx">addBands</span><span class="p">(</span><span class="nx">labels</span><span class="p">);</span>
</pre></div>
</div>
<p>will get the <code class="docutils literal notranslate"><span class="pre">id</span></code> (or <code class="docutils literal notranslate"><span class="pre">label</span></code>) for each of the image objects we created by segmenting the image, then add a layer to the image that labels each
pixel with the <code class="docutils literal notranslate"><span class="pre">id</span></code> of the object it’s part of. This is how we actually do the “object-based” part of the classification - the actual classification
is quite similar to the pixel-based method we’ve already seen.</p>
<p>After this, we can add the texture bands to our image:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="nx">img</span> <span class="o">=</span> <span class="nx">img</span><span class="p">.</span><span class="nx">addBands</span><span class="p">(</span><span class="nx">glcm</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s1">&#39;gray_asm&#39;</span><span class="p">))</span>
  <span class="c1">//.addBands(glcm.select(&#39;gray_contrast&#39;)) // uncomment to add contrast</span>
  <span class="c1">//.addBands(glcm.select(&#39;gray_ent&#39;)); // uncomment to add entropy</span>
</pre></div>
</div>
<p>To start with, we’ve only added the ASM layer. Once we’ve had a look at those results, we’ll see how adding additional texture layers changes the classification
results.</p>
<p>The next block:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="c1">// get the mean, std, and median values of all bands for each object</span>
<span class="kd">var</span> <span class="nx">img_mean</span> <span class="o">=</span> <span class="nx">img</span><span class="p">.</span><span class="nx">reduceConnectedComponents</span><span class="p">({</span>
  <span class="nx">reducer</span><span class="o">:</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Reducer</span><span class="p">.</span><span class="nx">mean</span><span class="p">(),</span>
  <span class="nx">labelBand</span><span class="o">:</span> <span class="s1">&#39;id&#39;</span>
<span class="p">});</span>

<span class="kd">var</span> <span class="nx">img_std</span> <span class="o">=</span> <span class="nx">img</span><span class="p">.</span><span class="nx">reduceConnectedComponents</span><span class="p">({</span>
  <span class="nx">reducer</span><span class="o">:</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Reducer</span><span class="p">.</span><span class="nx">stdDev</span><span class="p">(),</span>
  <span class="nx">labelBand</span><span class="o">:</span> <span class="s1">&#39;id&#39;</span>
<span class="p">});</span>

<span class="kd">var</span> <span class="nx">img_med</span> <span class="o">=</span> <span class="nx">img</span><span class="p">.</span><span class="nx">reduceConnectedComponents</span><span class="p">({</span>
  <span class="nx">reducer</span><span class="o">:</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Reducer</span><span class="p">.</span><span class="nx">median</span><span class="p">(),</span>
  <span class="nx">labelBand</span><span class="o">:</span> <span class="s1">&#39;id&#39;</span>
<span class="p">});</span>

<span class="kd">var</span> <span class="nx">pred_bands</span> <span class="o">=</span> <span class="nx">ee</span><span class="p">.</span><span class="nx">Image</span><span class="p">.</span><span class="nx">cat</span><span class="p">([</span>
  <span class="nx">img_mean</span><span class="p">,</span>
  <span class="nx">img_std</span><span class="p">,</span>
  <span class="nx">img_med</span>
<span class="p">]).</span><span class="kr">float</span><span class="p">();</span>
</pre></div>
</div>
<p>will calculate the mean, standard deviation, and median values for each object for each of the image bands
(surface reflectance, normalized difference indices, slope, ASM, contrast, and entropy, depending on which of lines 26–28 and 317–318 you’ve uncommented).
These are the values that will go into our classification - rather than the individual pixel values we used earlier.</p>
<p>When you run the script, you should see the confusion matrix, accuracy, and kappa values for the object-based classifer printed to the console
(note that this may take some time to finish):</p>
<a class="reference internal image-reference" href="../../../_images/obia_accuracy.png"><img alt="the error matrix and accuracy values for the OBIA classifier" class="align-center" src="../../../_images/obia_accuracy.png" style="width: 400px;" /></a>
<p>How does this compare to the pixel-based accuracy values? Try adding the contrast image (uncomment line 317) - how does this impact the
accuracy results?</p>
<p>What about if you add the entropy layer (uncomment line 318)?</p>
<p>Once you’ve trained a few different classifiers by commenting/uncommenting lines 26–28 and 317–318, you can move on to the
next part of the section (remove the <code class="docutils literal notranslate"><span class="pre">/*</span></code> from line 371 and the <code class="docutils literal notranslate"><span class="pre">*/</span></code> from line 398, then re-run the script).</p>
<p>The final part of this section will apply the OBIA classifier we’ve just trained, count the number of pixels belonging to
each classification, and then display the result in the map and the <strong>Console</strong>:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="c1">// apply the classification</span>
<span class="kd">var</span> <span class="nx">obia</span> <span class="o">=</span> <span class="nx">pred_bands</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="nx">pred_bands</span><span class="p">.</span><span class="nx">bandNames</span><span class="p">()).</span><span class="nx">classify</span><span class="p">(</span><span class="nx">classifier</span><span class="p">);</span>

<span class="c1">// add the classified layer to the map</span>
<span class="kd">var</span> <span class="nx">classPalette</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;013dd6&#39;</span><span class="p">,</span> <span class="s1">&#39;059e2a&#39;</span><span class="p">,</span> <span class="s1">&#39;a6613d&#39;</span><span class="p">,</span> <span class="s1">&#39;2aff53&#39;</span><span class="p">,</span> <span class="s1">&#39;e3d4ae&#39;</span><span class="p">,</span> <span class="s1">&#39;fffbf4&#39;</span><span class="p">];</span>

<span class="nb">Map</span><span class="p">.</span><span class="nx">addLayer</span><span class="p">(</span><span class="nx">obia</span><span class="p">,</span> <span class="p">{</span><span class="nx">min</span><span class="o">:</span> <span class="mf">0</span><span class="p">,</span> <span class="nx">max</span><span class="o">:</span> <span class="mf">5</span><span class="p">,</span> <span class="nx">palette</span><span class="o">:</span> <span class="nx">classPalette</span><span class="p">},</span> <span class="s1">&#39;OBIA Random Forest&#39;</span><span class="p">,</span> <span class="kc">true</span><span class="p">);</span>
<span class="nb">Map</span><span class="p">.</span><span class="nx">addLayer</span><span class="p">(</span><span class="nx">outline</span><span class="p">,</span> <span class="p">{</span><span class="nx">palette</span><span class="o">:</span> <span class="s1">&#39;ffffff&#39;</span><span class="p">},</span> <span class="s1">&#39;segments&#39;</span><span class="p">,</span> <span class="kc">false</span><span class="p">);</span>
</pre></div>
</div>
<p>We’ve also added the segments layer again, so that we can compare the classification with the object boundaries (you’ll need to
turn this on in the <strong>Layers</strong> menu):</p>
<a class="reference internal image-reference" href="../../../_images/obia_classified.png"><img alt="the OBIA classified image" class="align-center" src="../../../_images/obia_classified.png" style="width: 600px;" /></a>
<p>How does this classified image compare to the RF results? Where do you see big differences? Do the boundaries of the
classification line up with the image segments?</p>
<p>Have a look at the numeric results, as well - where are the biggest differences between the pixel-based results and
the object-based results? As you look around the map, do the classified results line up with what you expect to see?</p>
</section>
<section id="exporting-the-classification">
<h2>exporting the classification<a class="headerlink" href="#exporting-the-classification" title="Permalink to this headline"></a></h2>
<p>The code in this section will enable you to export the classified image to your Google Drive, and use them in, for example,
ArcGIS, QGIS, or ERDAS Imagine. To do so, uncomment this section (remove the <code class="docutils literal notranslate"><span class="pre">/*</span></code> from line 401 and the <code class="docutils literal notranslate"><span class="pre">*/</span></code> from line 409),
then re-run the script:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="nx">Export</span><span class="p">.</span><span class="nx">image</span><span class="p">.</span><span class="nx">toDrive</span><span class="p">({</span><span class="nx">image</span><span class="o">:</span> <span class="nx">obia</span><span class="p">.</span><span class="nx">select</span><span class="p">(</span><span class="s1">&#39;classification&#39;</span><span class="p">),</span>
  <span class="nx">description</span><span class="o">:</span> <span class="s1">&#39;OBIA Classification&#39;</span><span class="p">,</span>
  <span class="nx">scale</span><span class="o">:</span> <span class="mf">30</span><span class="p">,</span>
  <span class="nx">region</span><span class="o">:</span> <span class="nx">boundary</span><span class="p">,</span>
  <span class="nx">crs</span><span class="o">:</span> <span class="s1">&#39;epsg:32610&#39;</span><span class="p">,</span>
  <span class="nx">maxPixels</span><span class="o">:</span> <span class="mf">1e13</span>
<span class="p">});</span>
</pre></div>
</div>
</section>
<section id="next-steps">
<h2>next steps<a class="headerlink" href="#next-steps" title="Permalink to this headline"></a></h2>
</section>
<section id="references-and-notes">
<h2>references and notes<a class="headerlink" href="#references-and-notes" title="Permalink to this headline"></a></h2>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id1">3</a></span></dt>
<dd><p>Achanta, R. and S. Susstrunk (2017). In <em>Proc. IEEE Conf. Comp. Vis. Patt. Recog.</em>, pp. 4651–4660. doi: <a class="reference external" href="https://doi.org/10.1109/CVPR.2017.520">10.1109/CVPR.2017.520</a> [<a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Achanta_Superpixels_and_Polygons_CVPR_2017_paper.pdf">open-access pdf</a>]</p>
</dd>
<dt class="label" id="id5"><span class="brackets"><a class="fn-backref" href="#id2">4</a></span></dt>
<dd><p>Haralick, R. M., K. Shanmugam and I. Dinstein (1973). <em>IEEE Trans. Systems, Man, Cybernetics</em>, SMC-3(<strong>6</strong>), pp. 610-621. doi: <a class="reference external" href="http://doi.org/10.1109/TSMC.1973.4309314">10.1109/TSMC.1973.4309314.</a></p>
</dd>
<dt class="label" id="id6"><span class="brackets"><a class="fn-backref" href="#id3">5</a></span></dt>
<dd><p>Tassi, A. and M. Vizzari (2020). <em>Rem. Sens.</em> 12, 3776. doi: <a class="reference external" href="https://doi.org/10.3390/rs12223776">10.3390/rs12223776</a></p>
</dd>
</dl>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="pixel.html" class="btn btn-neutral float-left" title="pixel-based classification" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../change_detection/index.html" class="btn btn-neutral float-right" title="change detection" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Bob McNabb. Licensed under Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>