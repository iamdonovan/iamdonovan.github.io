

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>training, testing, and validation &#8212; space cameras and glaciers</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" href="../../../_static/customstyle.css" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../_static/design-tabs.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'teaching/ml-crash-course/exercises/training_testing';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="feature design and engineering" href="feature_design.html" />
    <link rel="prev" title="what is machine learning?" href="regression.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">space cameras and glaciers</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../whataboutbob.html">about me</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../index.html">teaching</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../../egm101/index.html">EGM101: skills toolbox</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../egm101/lectures.html">lectures</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../egm101/practicals/index.html">practicals</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../egm101/practicals/week5.html">computation, summary statistics, and graphing in excel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm101/practicals/week6.html">summarizing and graphing data in spss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm101/practicals/week7.html">correlation and regression in spss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm101/practicals/week8.html">hypothesis testing using spss</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../egm101/resources.html">additional resources</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../egm310/index.html">EGM310: introduction to gis and remote sensing</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../egm310/lectures.html">lectures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../egm310/resources.html">additional resources</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../egm702/index.html">EGM702: photogrammetry and advanced image analysis</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../egm702/lectures.html">lectures</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../egm702/practicals/index.html">practicals</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../egm702/practicals/setup.html">software setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm702/practicals/week1.html">dem processing using micmac</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm702/practicals/week2.html">dem differencing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm702/practicals/week3.html">introduction to google earth engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm702/practicals/week4.html">change detection in earth engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm702/practicals/week5.html">classification in earth engine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../egm702/resources.html">additional resources</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../egm703/index.html">EGM703: advanced active and passive remote sensing</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../egm703/lectures.html">lectures</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../egm703/practicals/index.html">practicals</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../egm703/practicals/week1.html">urban heat islands</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm703/practicals/week2.html">hyperspectral image analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm703/practicals/week3.html">SAR image processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm703/practicals/week4.html">InSAR Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm703/practicals/week5.html">SAR image interpretation and flood mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../egm703/resources.html">additional resources</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../egm722/index.html">EGM722: programming for gis and remote sensing</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../egm722/setup/index.html">setup</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/github.html">setting up github</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/git.html">installing git</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/desktop.html">installing github desktop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/fork.html">forking the repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/clone.html">cloning the repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/conda.html">setting up conda/anaconda</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/environment.html">setting up a conda environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/jupyter.html">configuring jupyter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/pycharm.html">pycharm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/setup/pip.html">installing packages with pip</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../egm722/lectures.html">lectures</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../egm722/practicals/index.html">practicals</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/practicals/pythonintro.html">intro to python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/practicals/debugging.html">debugging exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/practicals/cartopy.html">mapping with cartopy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/practicals/conflicts.html">conflict resolution (using git)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/practicals/vector.html">vector data using shapely and geopandas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/practicals/folium.html">interactive maps with folium</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/practicals/raster.html">raster data using rasterio</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/practicals/earthaccess.html">searching + downloading satellite data using earthaccess</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/practicals/zonalstats.html">zonal statistics using rasterstats</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../egm722/faq/index.html">help! something went wrong!</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/faq/git.html">git troubleshooting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/faq/python.html">python troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../egm722/project/index.html">programming project</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/project/github.html">creating a new github repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../egm722/project/environment.html">environment.yml</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../egm722/resources.html">additional resources</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../unis/index.html">unis glaciology (AG-325)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../unis/optical.html">mapping glacier area change</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../unis/dems.html">dem differencing and geodetic mass balance</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../python-programming/index.html">programming skills for phd researchers (using python)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../python-programming/setup/index.html">setup</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/setup/github.html">setting up github</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/setup/git.html">installing git</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/setup/desktop.html">installing github desktop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/setup/fork.html">forking the repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/setup/clone.html">cloning the repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/setup/conda.html">setting up conda/anaconda</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/setup/environment.html">setting up a conda environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/setup/jupyter.html">configuring the jupyterlab terminal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/setup/pycharm.html">pycharm</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../python-programming/lectures.html">lectures</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../python-programming/exercises/index.html">exercises</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/exercises/git.html">introduction to version control using git</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/exercises/project.html">starting a new project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/exercises/intro.html">introduction to python using jupyterlab</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/exercises/debugging.html">debugging code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/exercises/plotting.html">plotting data using seaborn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/exercises/pandas.html">working with pandas dataframes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/exercises/stats.html">basic statistical analysis using python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python-programming/exercises/regression.html">linear regression using python</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../python-programming/resources.html">additional resources</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../r-programming/index.html">programming skills for phd researchers (using R)</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../r-programming/setup/index.html">setup</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/setup/github.html">setting up github</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/setup/git.html">installing git</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/setup/desktop.html">installing github desktop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/setup/fork.html">forking the repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/setup/clone.html">cloning the repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/setup/conda.html">setting up conda/anaconda</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/setup/environment.html">setting up a conda environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/setup/jupyter.html">configuring jupyterlab</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../r-programming/lectures.html">lectures</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../r-programming/exercises/index.html">exercises</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/exercises/git.html">introduction to version control using git</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/exercises/project.html">starting a new project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/exercises/rintro.html">introduction to <strong>R</strong> using jupyterlab</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/exercises/debugging.html">debugging code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/exercises/plotting.html">plotting data using ggplot2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/exercises/transform.html">transforming data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/exercises/stats.html">basic statistical analysis using <strong>R</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../r-programming/exercises/regression.html">linear regression using <strong>R</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../r-programming/resources.html">additional resources</a></li>
</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../index.html">a crash course in machine learning (using python) – under development</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../setup.html">setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lectures.html">lectures</a></li>
<li class="toctree-l3 current active has-children"><a class="reference internal" href="index.html">exercises</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="regression.html">what is machine learning?</a></li>
<li class="toctree-l4 current active"><a class="current reference internal" href="#">training, testing, and validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="feature_design.html">feature design and engineering</a></li>
<li class="toctree-l4"><a class="reference internal" href="performance.html">measuring model performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../resources.html">additional resources</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../hpc-intro/index.html">introduction to high performance computing</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../hpc-intro/setup.html">setup</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../hpc-intro/shell/index.html">the unix shell</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../hpc-intro/shell/shell.html">in the beginning was the command line</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpc-intro/shell/navigation.html">navigating on the command line</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpc-intro/shell/files.html">working with files</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpc-intro/shell/input.html">input/output</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpc-intro/shell/scripts.html">shell scripts</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../hpc-intro/hpc/index.html">high performance computing</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../hpc-intro/hpc/atlas.html">atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpc-intro/hpc/data_transfer.html">transferring data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpc-intro/hpc/vulcan.html">vulcan</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../hpc-intro/resources.html">additional resources</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../dissertation/index.html">undergraduate dissertation projects</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dissertation/glaciers.html">mapping glacier changes over time</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dissertation/glacial_lakes.html">detection of supraglacial lakes and timing of drainage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dissertation/algae.html">mapping harmful algal blooms using satellite remote sensing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dissertation/floods.html">flood detection and monitoring using remote sensing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dissertation/wildfires.html">detection and mapping of wildfires</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dissertation/heat_islands.html">urban heat islands</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../gee/index.html">google earth engine</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../gee/tutorials/index.html">gee tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../gee/tutorials/getting_started/index.html">getting started</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/getting_started/adding_exporting.html">adding and exporting images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/getting_started/spectral.html">spectral signatures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/getting_started/image_collections.html">image collections and vectors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/getting_started/mapping.html">manual mapping (digitizing)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/getting_started/band_maths.html">band maths</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/getting_started/zonal_stats.html">zonal statistics</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../gee/tutorials/classification/index.html">image classification</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/classification/unsupervised.html">unsupervised classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/classification/pixel.html">pixel-based classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/classification/obia.html">object-based classification</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../gee/tutorials/change_detection/index.html">change detection</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/change_detection/visual_analysis.html">visual analysis of changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/change_detection/thresholding.html">band maths and thresholding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/change_detection/repeat_classification.html">repeat classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/change_detection/cva.html">change vector analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/change_detection/time_series.html">time series analysis</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../gee/tutorials/enhancement/index.html">image enhancement</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/enhancement/filtering.html">image filtering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/enhancement/pansharpening.html">pansharpening</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/enhancement/edge_detection.html">edge detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/enhancement/unmixing.html">spectral unmixing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/enhancement/pca.html">principle component analysis</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../gee/tutorials/advanced/index.html">advanced topics</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-33"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../gee/tutorials/advanced/animation.html">creating an animation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../gee/exercises/index.html">sample exercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../research/index.html">ongoing and past research projects</a><input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-34"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../research/dar.html">deplete and retreat (DaR)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../writing/index.html">selected writing samples</a><input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-35"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../writing/source.html">source magazine (summer 2022)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../github.html">github projects</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/iamdonovan/iamdonovan.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/iamdonovan/iamdonovan.github.io/edit/main/teaching/ml-crash-course/exercises/training_testing.rst" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/iamdonovan/iamdonovan.github.io/issues/new?title=Issue%20on%20page%20%2Fteaching/ml-crash-course/exercises/training_testing.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/teaching/ml-crash-course/exercises/training_testing.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>training, testing, and validation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data">data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#importing-libraries">importing libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-data-standardizing">preparing the data: standardizing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-data-splitting-partitioning">preparing the data: splitting/partitioning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-machine">support vector machine</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hinge-loss">hinge loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-scikit-learn">using scikit-learn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-the-results">checking the results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generalization">generalization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-kernel-trick">the “kernel trick”</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#radial-basis-function-kernel">radial basis function kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-kernels">polynomial kernels</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sigmoid-kernel">the sigmoid kernel</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">next steps</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="training-testing-and-validation">
<h1>training, testing, and validation<a class="headerlink" href="#training-testing-and-validation" title="Permalink to this heading">#</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is a <strong>non-interactive</strong> version of the exercise. If you want to run through the steps yourself and see the
outputs, you’ll need to do one of the following:</p>
<ul class="simple">
<li><p>follow the setup steps and work through the notebook on your own computer</p></li>
<li><p>open the workshop materials on <a class="reference external" href="https://mybinder.org/v2/gh/iamdonovan/ml-crash-course/HEAD">binder</a> and work
through them online</p></li>
</ul>
</div>
<p>In this exercise, we’ll have a look at some more fundamental concepts of
machine learning, including:</p>
<ul class="simple">
<li><p>standarization (similar to normalization seen previously)</p></li>
<li><p>splitting a dataset into training and testing (+validation)
partitions</p></li>
<li><p>overfitting/underfitting + generalization</p></li>
<li><p>kernel functions and the “kernel trick”</p></li>
</ul>
<p>We’ll look at all of this while also introducing <strong>support vector
machine</strong> (SVM) classification, a type of learning model that seeks to
classify data into one of two (or sometimes more) categories.</p>
<section id="data">
<h2>data<a class="headerlink" href="#data" title="Permalink to this heading">#</a></h2>
<p>The goal for this exercise will be to see if we can determine whether a
location is rainier or drier than average, based on other meteorological
parameters: namely, the average daily minimum temperature (<code class="docutils literal notranslate"><span class="pre">tmin</span></code>),
and the average monthly hours of sunshine (<code class="docutils literal notranslate"><span class="pre">sun</span></code>).</p>
<p>We’ll do this using a combination of historic meteorological
observations from the <a class="reference external" href="https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data">UK Met
Office</a>,
combined with climated averages from between 1971-2000 obtained from
<a class="reference external" href="https://data.gov.ie/dataset/met-eireann-1971-2000-climate-averages">Met
Éireann</a>.</p>
</section>
<section id="importing-libraries">
<h2>importing libraries<a class="headerlink" href="#importing-libraries" title="Permalink to this heading">#</a></h2>
<p>Before getting started, we will import the libraries (packages) that we
will use in the exercise:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/">sklearn</a>, for preprocessing our data
and doing the SVM classification;</p></li>
<li><p><a class="reference external" href="https://pandas.pydata.org/">pandas</a>, for reading the data from a
file;</p></li>
<li><p><a class="reference external" href="https://numpy.org/">numpy</a>, for working with arrays;</p></li>
<li><p><a class="reference external" href="https://matplotlib.org/">matplotlib</a>, for making plots.</p></li>
</ul>
<p>Remember that to do this, we use the <code class="docutils literal notranslate"><span class="pre">import</span></code> statement, followed by
the name of the package. We can also use <code class="docutils literal notranslate"><span class="pre">from</span></code> to import part of a
package, and we can <em>alias</em> the package name using <code class="docutils literal notranslate"><span class="pre">as</span></code>:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span><span class="p">,</span> <span class="n">model_selection</span><span class="p">,</span> <span class="n">preprocessing</span><span class="p">,</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
</pre></div>
</div>
<p>Next, we use <code class="docutils literal notranslate"><span class="pre">pd.read_csv()</span></code> to read the CSV file of the data:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/annual_values.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, let’s have a look at the data using <code class="docutils literal notranslate"><span class="pre">.head()</span></code>:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span> <span class="c1"># show the first 5 rows of data</span>
</pre></div>
</div>
<p>Here, each row corresponds to a station, with features including:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tmax</span></code>: average daily maximum temperature in °C;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tmin</span></code>: average daily minimum temperature in °C;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">air_frost</span></code>: average annual days of air frost (only for UK
stations);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rain</span></code>: average monthly precipitation in mm;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sun</span></code>: average monthly hours of sun;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">classification</span></code>: whether the station gets more (<code class="docutils literal notranslate"><span class="pre">rainy</span></code>) or less
(<code class="docutils literal notranslate"><span class="pre">dry</span></code>) precipitation than average.</p></li>
</ul>
<p>Before jumping into the machine learning part of the exercise, we’ll
first use <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> to make a plot showing <code class="docutils literal notranslate"><span class="pre">sun</span></code> vs <code class="docutils literal notranslate"><span class="pre">tmin</span></code>,
colored by `classification. This can help show us whether or not we
actually <em>can</em> separate rainy/dry locations using these two features:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># create a figure object with a single axis</span>

<span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;dry&#39;</span><span class="p">:</span> <span class="s1">&#39;orangered&#39;</span><span class="p">,</span> <span class="s1">&#39;rainy&#39;</span><span class="p">:</span> <span class="s1">&#39;royalblue&#39;</span><span class="p">}</span> <span class="c1"># create a dict of color</span>

<span class="c1"># for each value of classification, plot sun vs tmin using the colors defined above</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;classification&#39;</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">group</span><span class="o">.</span><span class="n">tmin</span><span class="p">,</span> <span class="n">group</span><span class="o">.</span><span class="n">sun</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

<span class="c1"># set the axis labels</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;avg min temp (°C)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;avg hours of sun&#39;</span><span class="p">)</span>

<span class="c1"># add a legend</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../../../_images/training_testing_7_1.png" src="../../../_images/training_testing_7_1.png" />
<p><br /> From the plot, we can see that it might be possible to draw a line
separating the two groups, but it’s made more difficult by noise: the
two groups are not nicely separated. That’s okay, because we will
discuss a few techniques to help deal with noise in our input data.</p>
</section>
<section id="preparing-the-data-standardizing">
<h2>preparing the data: standardizing<a class="headerlink" href="#preparing-the-data-standardizing" title="Permalink to this heading">#</a></h2>
<p>Have a look at the values of <code class="docutils literal notranslate"><span class="pre">sun</span></code> on the y axis (90 to 150 hours), vs
the values of <code class="docutils literal notranslate"><span class="pre">tmin</span></code> on the x axis (3 to 8 °C). Like we saw in the
previous exercise, having features with vastly different values can be a
problem for many machine learning algorithms. In particular, if the
variance of one feature is much larger than others, it may dominate the
objective function and cause the model to be unable to learn correctly
from the other features - similar to what we saw with the linear
regression example.</p>
<p>For SVM models, we want to make sure that the data are <em>centered</em> (i.e.,
the mean value is 0), with a unit variance (i.e., the variance is equal
to one). This helps ensure that the model is able to use all of the
features to learn from evenly.</p>
<p>First, we’ll create an <em>array</em> of feature values by indexing <code class="docutils literal notranslate"><span class="pre">tmin</span></code>
and <code class="docutils literal notranslate"><span class="pre">sun</span></code> from the <strong>DataFrame</strong>, then using <code class="docutils literal notranslate"><span class="pre">.to_numpy()</span></code>
(<a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html">documentation</a>)
to return an <span class="math notranslate nohighlight">\(N\times 2\)</span> array of values:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;tmin&#39;</span><span class="p">,</span> <span class="s1">&#39;sun&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="c1"># create the feature values</span>
</pre></div>
</div>
<p>SVM, like most machine learning algorithms, requires that our labels are
<em>numeric</em> - that is, we can’t use text like <em>dry</em> and <em>rainy</em> as labels,
we need to convert these to numbers. We’ll cover more sophisticated ways
to encode text features when we cover feature engineering in the next
exercise. For now, we can use <code class="docutils literal notranslate"><span class="pre">.map()</span></code>
(<a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html">documentation</a>)
along with a <strong>dict</strong> to replace <code class="docutils literal notranslate"><span class="pre">'dry'</span></code> with a value of <code class="docutils literal notranslate"><span class="pre">-1</span></code> and
<code class="docutils literal notranslate"><span class="pre">'rainy'</span></code> with a value of <code class="docutils literal notranslate"><span class="pre">1</span></code>, then use <code class="docutils literal notranslate"><span class="pre">.to_numpy()</span></code> to convert
this to a <code class="docutils literal notranslate"><span class="pre">numpy</span></code> array:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;classification&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;dry&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;rainy&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="c1"># create a vector of numeric labels</span>
</pre></div>
</div>
<p>In order to <em>standardize</em> the features, we first create a
<strong>StandardScaler</strong> object
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">documentation</a>),
then use <code class="docutils literal notranslate"><span class="pre">.fit()</span></code>
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit">documentation</a>)
to compute the mean and standard deviation to use for scaling.</p>
<p>Then, we use <code class="docutils literal notranslate"><span class="pre">.transform()</span></code>
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform">documentation</a>)
to actually standardize, using the calculated mean and standard
deviation:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="c1"># calculate the mean and standard deviation using fit</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="c1"># apply the standardization to the feature values</span>
</pre></div>
</div>
<p>Now, we should see that the mean of each vector is (very nearly) zero,
using <code class="docutils literal notranslate"><span class="pre">.mean()</span></code>
(<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.mean.html">documentation</a>):</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled_features</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># mean should be very nearly zero</span>
</pre></div>
</div>
<p>And, we can use <code class="docutils literal notranslate"><span class="pre">.var()</span></code>
(<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.var.html">documentation</a>)
to check that the variance of each vector is equal to 1:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled_features</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># variance should be nearly equal to one</span>
</pre></div>
</div>
<p>Now we can plot the scaled values of <code class="docutils literal notranslate"><span class="pre">tmin</span></code> and <code class="docutils literal notranslate"><span class="pre">sun</span></code>, colored by
the numeric labels, to see that the data should still look the same -
just scaled differently:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">scaled_features</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orangered&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;dry&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">scaled_features</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;royalblue&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;rainy&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;avg min temp (°C)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;avg hours of sun&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../../../_images/training_testing_19_1.png" src="../../../_images/training_testing_19_1.png" />
</section>
<section id="preparing-the-data-splitting-partitioning">
<h2>preparing the data: splitting/partitioning<a class="headerlink" href="#preparing-the-data-splitting-partitioning" title="Permalink to this heading">#</a></h2>
<p>Now that we’ve standardized our features and converted our text labels
into numbers, we are nearly ready to train the classifier. I say nearly
ready, because there’s one last important step: <strong>partitioning</strong> our
data into training, testing, and valdiation datasets.</p>
<p>The reason that we do this is that we want to be able to evaluate how
well the model has learned. We want to avoid having the model only do
well at predicting labels for examples it has already seen - we want to
make sure that the model <strong>generalizes</strong> to previously unseen data, so
that we know it isn’t simply regurgitating the answers to questions it
has memorized.</p>
<p>In practice, we use the <strong>training</strong> dataset to actually build the model
- this is the data that the model “learns” the parameters for. The
<strong>validation</strong> dataset is what we use to help determine which learning
algorithm to use, and to find the best values of model hyperparameters,
and the <strong>testing</strong> dataset is how we assess the model performance once
we are sure we have found the optimal model hyperparameters. The
training dataset is typically the largest of the three, while the
testing and validation datasets are typically the same size. How big
each partition is depends on the size of the dataset - a common rule of
thumb is to use 70% of the data for training and 15% each for testing
and validation; with extremely large datasets, the split might be more
extreme.</p>
<p>We can use <code class="docutils literal notranslate"><span class="pre">model_selection.train_test_split()</span></code>
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">documentation</a>)
to actually do the split - note that in order to get three partitions
(training, testing, and validation), we need to run this split twice -
first to get the training partition, then again to get the testing and
validation partitions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># use 70% of the data for training, 15% for testing, 15% for validation</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Because we have a small dataset (<span class="math notranslate nohighlight">\(n=49\)</span>), we’re only going to
split into training and testing partitions, because we want to make sure
that we have enough observations in our dataset to get a good picture of
the model performance.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># use 70% of the data for training, 15% for testing, 15% for validation</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that by specifying the <code class="docutils literal notranslate"><span class="pre">random_state</span></code> argument, we ensure that
the split will be the same each time we run this (even on other
computers). In practice, we may want to have a truly random split each
time we run the data - in this case, we would omit this argument.</p>
<p>Now, we can plot the two datasets side-by-side to compare them.
Hopefully, they should look fairly similar - if not, we may have a more
challenging time training and evaluating our model:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">XY</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">],</span> <span class="p">[</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">])):</span>
    <span class="n">X_</span><span class="p">,</span> <span class="n">y_</span> <span class="o">=</span> <span class="n">XY</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_</span><span class="p">[</span><span class="n">y_</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_</span><span class="p">[</span><span class="n">y_</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orangered&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;dry&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_</span><span class="p">[</span><span class="n">y_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_</span><span class="p">[</span><span class="n">y_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;royalblue&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;rainy&#39;</span><span class="p">)</span>

    <span class="n">axs</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;avg min temp (°C)&#39;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;avg hours of sun&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;training data&#39;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;testing data&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../../../_images/training_testing_23_0.png" src="../../../_images/training_testing_23_0.png" />
</section>
<section id="support-vector-machine">
<h2>support vector machine<a class="headerlink" href="#support-vector-machine" title="Permalink to this heading">#</a></h2>
<p>Now that we have partitioned our dataset, we’re ready to train our
model. In this exercise, we’ll explore using support vector machine
(SVM) classification. In its basic form, SVM is trying to find
parameters <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> and <span class="math notranslate nohighlight">\(b\)</span> such that:</p>
<div class="math notranslate nohighlight">
\[\mathbf{wx}_i - b \geq 1, y_i = 1\]</div>
<div class="math notranslate nohighlight">
\[\mathbf{wx}_i - b \leq -1, y_i = -1\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> are vectors with
dimension equal to the number of features in our dataset, and
<span class="math notranslate nohighlight">\(y_i\)</span> is the label for the feature vector <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span>.</p>
<p>Alternatively, we can write the constraints like this:</p>
<div class="math notranslate nohighlight">
\[y_i (\mathbf{wx}_i - b) \geq 1\]</div>
<p>Another way of saying all of this is that we’re trying to find a
<strong>hyperplane</strong>, also called the <strong>decision boundary</strong>, that separates
two classes in feature space by the largest <strong>margin</strong> (distance between
the closest examples of each class) possible. To do this, we need to
minimize the <strong>Euclidean norm</strong> of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>,
<span class="math notranslate nohighlight">\(\lVert\mathbf{w}\rVert\)</span>:</p>
<div class="math notranslate nohighlight">
\[\lVert\mathbf{w}\rVert = \sqrt{\sum_j w_j^2}\]</div>
<p>Because the distance between the two hyperplanes defined by
<span class="math notranslate nohighlight">\(\mathbf{wx}_i - b = \pm 1\)</span> is <span class="math notranslate nohighlight">\(2 / \lVert\mathbf{w}\rVert\)</span>,
by minimizing <span class="math notranslate nohighlight">\(\lVert\mathbf{w}\rVert\)</span>, we get the maximum
distance between the two planes. We’ll stick to two dimensions for now
because it’s easier to visualize - in this case, what we’re trying to
find is a line that separates the two classes.</p>
<section id="hinge-loss">
<h3>hinge loss<a class="headerlink" href="#hinge-loss" title="Permalink to this heading">#</a></h3>
<p>As we can see above, there is no line that will cleanly separate these
two classes - in this case, we use something called the <strong>hinge loss</strong>
function:</p>
<div class="math notranslate nohighlight">
\[\max(0, 1 - y_i (\mathbf{wx}_i - b))\]</div>
<p>Values that are on the “correct” side of the decision boundary have a
loss of 0; values that are on the “wrong” side have a loss that is
proportional to the distance from the decision boundary. In this case,
the cost function looks like:</p>
<div class="math notranslate nohighlight">
\[C \lVert\mathbf{w}\rVert^2 + \frac{1}{N}\sum_i \max(0, 1 - y_i (\mathbf{wx}_i - b))\]</div>
<p>where <span class="math notranslate nohighlight">\(C\)</span> is a <em>positive</em> hyperparameter that determines the
tradeoff between increasing the size of the decision boundary and
ensuring that each feature <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> is on the correct side
of the decision boundary. Increasing the value of <span class="math notranslate nohighlight">\(C\)</span> means that
we place less emphasis on misclassification; decreasing the value of
<span class="math notranslate nohighlight">\(C\)</span> means that we have a smaller margin size. We will come back to
this more in later exercises, when we talk about something called
<strong>regularization</strong>.</p>
</section>
<section id="using-scikit-learn">
<h3>using scikit-learn<a class="headerlink" href="#using-scikit-learn" title="Permalink to this heading">#</a></h3>
<p>To do this using <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>, we need to first create an object of
the <strong>class</strong> corresponding to our machine learning algorithm - in this
case, we’re using support vector classification, so we use <code class="docutils literal notranslate"><span class="pre">svm.SVC</span></code>
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">documentation</a>).
In the documentation, you can see that one of the input arguments to
<code class="docutils literal notranslate"><span class="pre">svm.SVC()</span></code> is <code class="docutils literal notranslate"><span class="pre">C</span></code> - the “regularization parameter” discussed in the
previous paragraphs. For now, we will stick with the default value of
<code class="docutils literal notranslate"><span class="pre">1.0</span></code>, but in later exercises we will experiment with changing this.</p>
<p>As we will explore more later, we can also specify what kind of
<code class="docutils literal notranslate"><span class="pre">kernel</span></code> to use for the classifier - to start, we’ll use the “classic”
version, where the decision boundary is linear:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear_clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span> <span class="c1"># create an SVC object with a linear kernel</span>
</pre></div>
</div>
<p>Just like with <code class="docutils literal notranslate"><span class="pre">LinearRegression()</span></code>, we use the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> method
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">documentation</a>)
to train the model using our training data:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># train the classifier using the training data</span>
</pre></div>
</div>
<p>And that’s it. To view the decision boundary, we can write the following
function, which uses <code class="docutils literal notranslate"><span class="pre">.decision_function()</span></code>
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.decision_function">documentation</a>)
along with a grid of feature values to create a mesh that displays the
location of the decision boundary:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_decision_surface</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">clf</span><span class="p">):</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s2">&quot;orangered&quot;</span><span class="p">,</span><span class="s2">&quot;royalblue&quot;</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;from_list&#39;</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># plot the input data</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orangered&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;dry&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;royalblue&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;rainy&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;testing data&#39;</span><span class="p">)</span>
    <span class="c1"># create a grid of feature value points to show the decision boundary</span>
    <span class="n">XX</span><span class="p">,</span> <span class="n">YY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="o">-</span><span class="mf">3.5</span><span class="p">:</span><span class="mf">3.5</span><span class="p">:</span><span class="mi">200</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">:</span><span class="mi">3</span><span class="p">:</span><span class="mi">200</span><span class="n">j</span><span class="p">]</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">XX</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">YY</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># show the decision boundary</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">Z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>

    <span class="c1"># show the contours</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">],</span> <span class="n">linestyles</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">],</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>
</pre></div>
</div>
<p>When we run this function, we can see how the classifier has done:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_decision_surface</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">linear_clf</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../../_images/training_testing_31_0.png" src="../../../_images/training_testing_31_0.png" />
<p><br /> As we identified when we first plotted the data, it is difficult to
fully separate these two classes by a straight line - there’s some
overlap between them. What we do see with the training data (small
individual circles) is that the majority of the points lie on the
correct side of the line, even if there are a number of “rainy” points
that would be classified as dry using the classifier, and a few “dry”
points that would be classified as rainy.</p>
</section>
</section>
<section id="checking-the-results">
<h2>checking the results<a class="headerlink" href="#checking-the-results" title="Permalink to this heading">#</a></h2>
<p>We’ll cover formal ways to assess model performance more in the next
exercise, but for now we can look at the <strong>mean accuracy</strong> using
<code class="docutils literal notranslate"><span class="pre">.score()</span></code>
(<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.score">documentation</a>)
- this is the proportion of labels that the model correctly predicted.
For our training data, we can see that the proportion is fairly high,
though not perfect - around 83%:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># get the mean accuracy for the training data</span>
</pre></div>
</div>
<p>We can also test the score using our test data - here, we can see that
it’s a bit lower at 80%:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="c1"># get the mean accuracy for the testing data</span>
</pre></div>
</div>
</section>
<section id="generalization">
<h2>generalization<a class="headerlink" href="#generalization" title="Permalink to this heading">#</a></h2>
<p>Ideally, we would like to see our model perform about the same on both
the training data and the testing/validation data. When this is the
case, as it is here, it’s a good indication that our model
<strong>generalizes</strong> well - that it’s not simply regurgitating “answers” that
it memorized during the training process.</p>
<p>In machine learning, we are ultimately more interested in minimizing the
loss on unseen or new data than we are in minimizing the loss on our
training data, because it’s the unseen data that our model will be used
to help classify. If our model fails to generalize, it will be far less
useful in practice.</p>
<p>This leads us to two other concepts: <strong>underfitting</strong> and
<strong>overfitting</strong>. A model that <strong>underfits</strong> doesn’t do a very good job
predicting the labels of the training data. This can happen for a
variety of reasons, but the most common are that the model is too simple
for the data, or the features that we are using are poor predictors for
our labels. In the first case, we might need to consider a more
complicated model; in the second case, we may need to add features that
have a more meaningful relationship (“higher predictive power”) with the
label.</p>
<p>A model that <strong>overfits</strong> typically does a very good job of predicting
using the training data, but a very poor job when it sees data that it
has not been trained on. As with underfitting, this can happen for a
variety of reasons. The most common reasons are that the model is too
complex for the data, or that we have too many features and not enough
training examples. In the first case, we would need to consider a
simpler model; in the second, we need to reduce the number of features,
or increase the number of training examples that we have.</p>
<p>As we continue through the rest of this workshop, I will try to
highlight examples of problems where the model is overfit or underfit,
and illustrate potential solutions to these problems.</p>
</section>
<section id="the-kernel-trick">
<h2>the “kernel trick”<a class="headerlink" href="#the-kernel-trick" title="Permalink to this heading">#</a></h2>
<p>Very often with real datasets, we will be unable to find a “clean” split
between classes - we will either have <strong>noise</strong> in our input data, or we
will have some kind of inherent non-linearity in our data. We have
already seen an example of how SVM can be used in the first case, by
introducing a tradeoff between the margin size and the “cost” of
misclassification. This doesn’t normally suffice when we have inherent
non-linearity in our data, but there is an alternative solution: very
often, we can transform our original space into a higher-dimensional
space where there is a “nice” linear separation between classes.</p>
<p>The problem with this is that it can be very costly to find an
appropriate transformation - we don’t know what this transformation
looks like beforehand, which means we would need to try many such
transformations and train our classifier in each of them.</p>
<p>Fortunately, we don’t actually have to do this in practice - instead, we
can use something known as the <strong>kernel trick</strong>. By using something
known as a <strong>kernel function</strong> (or just a <strong>kernel</strong>), we can
efficiently and implicitly transform our input features into a
higher-dimensional space.</p>
<p>We will not go into the mathematical details of how this all works here
- instead, we will look at some examples of different <strong>kernel
functions</strong>, and see how this impacts the classifier training.</p>
<section id="radial-basis-function-kernel">
<h3>radial basis function kernel<a class="headerlink" href="#radial-basis-function-kernel" title="Permalink to this heading">#</a></h3>
<p>One of the most common kernel functions in practice is the <strong>radial
basis function</strong> (<strong>RBF</strong>) kernel - indeed, this is actually the default
kernel for <code class="docutils literal notranslate"><span class="pre">svm.SVC</span></code>. The RBF kernel has the form:</p>
<div class="math notranslate nohighlight">
\[k(\mathbf{x}_1, \mathbf{x}_2) = \exp(-\gamma\cdot \lVert\mathbf{x}_1 - \mathbf{x}_2\rVert^2)\]</div>
<p>where <span class="math notranslate nohighlight">\(\lVert\mathbf{x}_1 - \mathbf{x}_2\rVert^2\)</span> is the squared
<strong>Euclidean distance</strong> between two vectors <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{x}_2\)</span>. Varying the value of the hyperparameter
<span class="math notranslate nohighlight">\(\gamma\)</span> (<code class="docutils literal notranslate"><span class="pre">gamma</span></code>) helps determine whether the decision boundary
in the original space is curved or smooth by changing the influence of
each training sample on the decision boundary.</p>
<p>In the example below, we first use <code class="docutils literal notranslate"><span class="pre">svm.SVC</span></code> to create a new
classifier object, using the <code class="docutils literal notranslate"><span class="pre">kernel</span></code> argument to specify an RBF
kernel. We’ll use the default value of <code class="docutils literal notranslate"><span class="pre">gamma='scale'</span></code>, which means
that the value of <code class="docutils literal notranslate"><span class="pre">gamma</span></code> is calculated as <span class="math notranslate nohighlight">\(1 / N\sigma_X\)</span>,
where <span class="math notranslate nohighlight">\(N\)</span> is the number of features and <span class="math notranslate nohighlight">\(\sigma_X\)</span> is the
variance of the input features:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rbf_clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">)</span> <span class="c1"># create a new classifier object with an RBF kernel</span>
</pre></div>
</div>
<p>As before, we train the classifier using <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> and our training
dataset:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rbf_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># train the classifier with the training data</span>
</pre></div>
</div>
<p>And now, we can use <code class="docutils literal notranslate"><span class="pre">plot_decision_surface()</span></code> to show the decision
boundary along with the training and testing data:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_decision_surface</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">rbf_clf</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../../_images/training_testing_41_0.png" src="../../../_images/training_testing_41_0.png" />
<p><br /> Here, we see that the shape of the decision boundary is very different
to the linear model. We can also see that while the results look fairly
good for the training data, there are more testing data that are on the
“wrong” side of the decision boundary.</p>
<p>To check this, we can look at the mean accuracy of the training data
using <code class="docutils literal notranslate"><span class="pre">.score()</span></code>:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rbf_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
<p>and for the testing data:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rbf_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<p>So, we have a small improvement in the mean accuracy for the training
data (0.833 vs 0.829), but it has come with a large decrease in the mean
accuracy for the testing data: 0.533 vs 0.8. This is strong indication
that our model has <strong>overfit</strong> the training data: the performance on
“new” data (the testing data) is much worse than what we saw in
training, indicating that the model has learned the peculiarities of the
training data.</p>
<p>With additional training data, we might be able to improve performance
in both training and testing; for now, though, we’ll leave this and look
at a different kernel example.</p>
</section>
<section id="polynomial-kernels">
<h3>polynomial kernels<a class="headerlink" href="#polynomial-kernels" title="Permalink to this heading">#</a></h3>
<p>The next kernel we will look at is the <strong>polynomial kernel</strong>, which has
the form:</p>
<div class="math notranslate nohighlight">
\[k(\mathbf{x}_1, \mathbf{x}_2) = (\gamma\cdot\mathbf{x}_1^\top\mathbf{x}_2 + r)^d\]</div>
<p>where <span class="math notranslate nohighlight">\(d\)</span> is the degree (<code class="docutils literal notranslate"><span class="pre">degree</span></code>) of the polynomial,
<span class="math notranslate nohighlight">\(\gamma\)</span> (<code class="docutils literal notranslate"><span class="pre">gamma</span></code>) controls how much each training sample
influences the shape of the decision boundary and <span class="math notranslate nohighlight">\(r\)</span> is the bias
term (<code class="docutils literal notranslate"><span class="pre">coef0</span></code>) that shifts the value of the polynomial up or down. By
default with <code class="docutils literal notranslate"><span class="pre">svm.SVC</span></code>, <code class="docutils literal notranslate"><span class="pre">gamma</span></code> is calculated as
<span class="math notranslate nohighlight">\(1 / N\sigma_X\)</span>; <code class="docutils literal notranslate"><span class="pre">degree</span></code> equals 3 (i.e., a cubic polynomial);
and <code class="docutils literal notranslate"><span class="pre">coef0</span></code> equals 0.</p>
<p>As before, we’ll use the default values to begin, but feel free to vary
the different hyperparameters to see if you are able to improve the
model performance.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poly_clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">)</span> <span class="c1"># create a new classifier object with a third-degree polynomial kernel</span>
</pre></div>
</div>
<p>As before, we train the classifier using <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> and our training
dataset:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poly_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># train the classifier with the training data</span>
</pre></div>
</div>
<p>And now, we can use <code class="docutils literal notranslate"><span class="pre">plot_decision_surface()</span></code> to show the decision
boundary along with the training and testing data:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_decision_surface</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">poly_clf</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../../_images/training_testing_51_0.png" src="../../../_images/training_testing_51_0.png" />
<p><br /> Here, we see that the shape of the decision boundary is more similar to
the linear model than what we saw with the RBF kernel. We can also see
that while the results look fairly good for the training data, there are
a lot more testing data that are on the “wrong” side of the decision
boundary.</p>
<p>Now, let’s look at the mean accuracy of the training data using
<code class="docutils literal notranslate"><span class="pre">.score()</span></code>:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poly_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># calculate the mean accuracy of the training data</span>
</pre></div>
</div>
<p>The results here are slightly worse than the accuracy we obtained with
both the linear and RBF kernels, though not by much. The testing data:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poly_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="c1"># calculate the mean accuracy of the testing data</span>
</pre></div>
</div>
<p>show a similar result as the RBF kernel - the model has overfit the
training data, and as a result, the accuracy using the testing data is
quite poor.</p>
</section>
<section id="the-sigmoid-kernel">
<h3>the sigmoid kernel<a class="headerlink" href="#the-sigmoid-kernel" title="Permalink to this heading">#</a></h3>
<p>The final kernel function that we will look at is the <strong>sigmoid</strong> kernel
function, which has the form:</p>
<div class="math notranslate nohighlight">
\[k(\mathbf{x}_1, \mathbf{x}_2) = \tanh(\gamma\cdot\mathbf{x}_1^\top\mathbf{x}_2 + r)\]</div>
<p>where <span class="math notranslate nohighlight">\(\tanh\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Hyperbolic_functions#Definitions">hyperbolic tangent
function</a>.
As with the polynomial kernel, <span class="math notranslate nohighlight">\(\gamma\)</span> (<code class="docutils literal notranslate"><span class="pre">gamma</span></code>) controls how
much each training sample influences the shape of the decision boundary
and <span class="math notranslate nohighlight">\(r\)</span> is the bias term (<code class="docutils literal notranslate"><span class="pre">coef0</span></code>) that shifts the data up or
down.</p>
<p>As before, we will use the default values of <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">coef0</span></code>,
but feel free to experiment with different values later on:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sig_clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span> <span class="c1"># create a new classifier object with a sigmoid kernel</span>
</pre></div>
</div>
<p>Next, train the classifier using <code class="docutils literal notranslate"><span class="pre">.fit()</span></code>:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sig_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># train the classifier with the training data</span>
</pre></div>
</div>
<p>and use <code class="docutils literal notranslate"><span class="pre">plot_decision_surface()</span></code> to show the shape of the decision
boundary along with the training and testing data:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_decision_surface</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">sig_clf</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../../_images/training_testing_61_0.png" src="../../../_images/training_testing_61_0.png" />
<p><br /> With the <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> kernel, it looks like we have a number of points on
the “wrong” side of the decision boundary for both classes, indicating
that the training score will likely be lower than the other examples. We
can verify this using <code class="docutils literal notranslate"><span class="pre">.score()</span></code> and the training data:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sig_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># calculate the mean accuracy of the training data</span>
</pre></div>
</div>
<p>and for the testing data:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sig_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="c1"># calculate the mean accuracy of the testing data</span>
</pre></div>
</div>
<p>Here we see something interesting - the model had a higher mean accuracy
on the testing data than the training data, indicating that it
generalized better than the other models, even if the training results
were noticeably worse than the other models (i.e., it <strong>underfit</strong> the
training data). After all of this, we can see that the original SVM
formulation, with a linear decision boundary, has performed the best
with our data, both in terms of training and testing. It turns out that
despite their simplicity, linear models can be a very good choice for
generalizing - especially when we don’t have a strong reason to assume
that our model needs to be more complex.</p>
</section>
</section>
<section id="next-steps">
<h2>next steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">#</a></h2>
<p>That’s all for this exercise. For additional practice, try at least one
of the suggestions below</p>
<ul class="simple">
<li><p>Try varying the different hyperparameters for at least one of the
kernel functions (<code class="docutils literal notranslate"><span class="pre">rbf</span></code>, <code class="docutils literal notranslate"><span class="pre">poly</span></code>, or <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code>) introduced
above. Are you able to improve the training accuracy, as well as the
testing accuracy?</p></li>
<li><p>Instead of using <code class="docutils literal notranslate"><span class="pre">tmax</span></code> as an input feature, try using <code class="docutils literal notranslate"><span class="pre">tmax</span></code> -
does this improve, or worsen, the results? Why do you think this
might be?</p></li>
<li><p>Try adding dimensionality by using <code class="docutils literal notranslate"><span class="pre">tmin</span></code>, <code class="docutils literal notranslate"><span class="pre">tmax</span></code>, and <code class="docutils literal notranslate"><span class="pre">sun</span></code> as
input features. How does this change the results? Does it depend on
the kernel function used?</p></li>
<li><p>Try different combinations of <code class="docutils literal notranslate"><span class="pre">tmax</span></code> and <code class="docutils literal notranslate"><span class="pre">tmin</span></code> (e.g., <code class="docutils literal notranslate"><span class="pre">tmax</span></code> -
<code class="docutils literal notranslate"><span class="pre">tmin</span></code>, <code class="docutils literal notranslate"><span class="pre">tmax</span></code> + <code class="docutils literal notranslate"><span class="pre">tmin</span></code>, etc.). Are there kernel functions for
which this is better or worse?</p></li>
</ul>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="regression.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">what is machine learning?</p>
      </div>
    </a>
    <a class="right-next"
       href="feature_design.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">feature design and engineering</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data">data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#importing-libraries">importing libraries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-data-standardizing">preparing the data: standardizing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-data-splitting-partitioning">preparing the data: splitting/partitioning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-machine">support vector machine</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hinge-loss">hinge loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-scikit-learn">using scikit-learn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-the-results">checking the results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generalization">generalization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-kernel-trick">the “kernel trick”</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#radial-basis-function-kernel">radial basis function kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-kernels">polynomial kernels</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sigmoid-kernel">the sigmoid kernel</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">next steps</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Bob McNabb
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Bob McNabb. Licensed under Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0).
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>